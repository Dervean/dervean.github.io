---
layout: post
title: "大数据系统: 初识 Hadoop"
author: Dervean
description: "初识 Hadoop"
categories: [hadoop]
tags: [hadoop,linux]
redirect_from:
  - /2018/03/30/
---

大数据系统与大规模数据处理作业，要求环境:

- jdk-1.7
- ubuntu-14.04
- hadoop-2.6.0
- HBase-0.98

---

* Kramdown table of contents
{:toc .toc}

# Hadoop 环境配置

## JDK-1.7

我的 ubuntu 系统版本是 16.04 LTS，jdk 版本是 openjdk-1.8，要求版本是 1.7，需要切换 jdk 版本，但是 16.04 安装源已经没有 openjdk7 了，直接 sudo apt-get install openjdk-7-jdk 会提示 "没有可安装候选"，需要手动添加仓库:

- sudo add-apt-repository ppa:openjdk-r/ppa
- sudo apt-get update
- sudo apt-get install openjdk-7-jdk

然后可以随时切换 jdk 版本:

- sudo update-alternatives --config java
- sudo update-alternatives --config javac

## hadoop-2.6.5

在网上没找到 2.6.0 版本的 hadoop，所以将就着用 2.6.5 版本的，虽然全程按照网上的教程配置的，但也遇到了一些问题，以下是搭建伪分布式环境步骤:

1. 查看 host 文件:

   - cat /etc/hosts

   我的 hostname 是 localhost，这个名称待会用于配置文件，因为我搭建的是伪分布式环境，所以 master node 和 slave node 都是本地，如果要搭建完全分布式环境，要把每台机子的 host 名称以及 ip 都写入 hosts 文件里面。

2. 免密码连入

   免密码连入是为了让 node 之间的数据交流免除输入密码的限制，即使是伪分布式也要做到这一点。

   - ssh-keygen -t rsa
   - cd ~/.ssh
   - cp id_rsa.pub authorized_keys

   按照网上的教程，这里应该能够实现免密码 ssh localhost 才对，但是却报错误:

   $$
   \text{"sign_and_send_pubkey: signing failed: agent refused operation"}
   $$

   起初我怀疑是 authorized_keys 没有生效的原因，所以取消了 /etc/ssh/sshd_config 里面的注释:

   - #AuthorizedKeysFile	%h/.ssh/authorized_keys

   另外更改权限:

   - chmod 700 ~/.ssh
   - chmod 600 ~/.ssh/authorized_keys

   但仍没有解决上述问题，网上有一个解决方法:

   - eval “$(ssh-agent)”
   - ssh-add

   ssh-agent 用于管理密钥，ssh-add 将密钥加入到 ssh-agent 中，ssh 和 ssh-agent 通信获取密钥。可以通过 ssh-add -l 查看附加了哪些 key。

   但这种方法只能在当前的 terminal 起作用，重新开一个 terminal 就得重新执行上述命令才行。

   最终我重打开一个 terminal 直接执行:

   - ssh-add

   竟然成功了，当然我也没弄懂其中缘由，可能这就是天意吧 :)

3. 安装 hadoop-2.6.5

   下载 hadoop-2.6.5.tar.gz 并解压:

   - tar xzvf hadoop-2.6.5.tar.gz ~/Hadoop/hadoop-2.6.5

   然后在 hadoop-2.6.5 目录下修改以下文件:

   - ./etc/hadoop/hadoop-env.sh

   export JAVA_HOME= /usr/lib/jvm/java-7-openjdk-amd64

   - ./etc/hadoop/core-site.xml

~~~xml
   <configuration>
		<property>
			<name>fs.default.name</name>
			<value>hdfs://localhost:9000</value>
			<final>true</final>
		</property>

		<property>
			<name>hadoop.tmp.dir</name>
			<value>/home/dervean/Hadoop/hadoop-2.6.5/tmp</value>
			<description>A base for other temporary directories</description>
		</property>
	</configuration>
~~~

   分别是：设置 master 的 NameNode 的 IP 以及监听端口；设置存放每次运行的作业信息的临时目录。

   - ./etc/hadoop/hdfs-site.xml

~~~xml
	<configuration>
		<property>
			<name>dfs.name.dir</name>
			<value>file:/home/dervean/Hadoop/hadoop-2.6.5/name</value>
			<final>true</final>
		</property>
	
		<property>
			<name>dfs.data.dir</name>
			<value>file:/home/dervean/Hadoop/hadoop-2.6.5/data</value>
			<final>true</final>
		</property>
	
		<property>
			<name>dfs.replication</name>
			<value>1</value>
			<final>true</final>
		</property>
	
		<property>
			<name>dfs.permissions</name>
			<value>false</value>
		</property>
	</configuration>
~~~

   分别是：设置 NameNode 存储元数据的目录；设置 DataNode 存放数据块的目录；设置副本数目；设置访问权限。

   注意必须使用规范的 URI 格式（即: file:/home/dervean/Hadoop/hadoop-2.6.5/data 不要缺失 "file:"）。

   - ./etc/hadoop/mapred-site.xml

~~~xml
	<configuration>
		<property>
			<name>mapred.job.tracker</name>
			<value>localhost:9001</value>
		</property>
	</configuration>
~~~

   设置 JobTracker 的 IP 以及监听端口。

   - ./etc/hadoop/slaves

   localhost

   因为是伪分布式，所以 slave 也是 localhost。

   - 也可以修改 /etc/profile 文件将 hadoop 命令全部加入环境变量里面，我并没有没有做这一步。

4. 最终可以尝试启动集群，此时仍在 hadoop-2.6.5 文件夹内:

   - ./bin/hadoop namenode -format

   格式化操作**只需要一次**即可。

   - ./sbin/start-all.sh

   查看启动情况:

   - jps

   如果出现 NameNode、NodeManager、ResourceManager、SecondaryNameNode、DataNode 这五个进程则说明启动成功。

   遇到一些问题的话可以从 hadoop-2.6.5 目录下的 logs 目录中查找相关内容。

## HBase-0.98















