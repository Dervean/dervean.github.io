---
layout: post
title: "Hadoop: 环境配置"
author: Dervean
description: "初识 Hadoop"
categories: [hadoop]
tags: [hadoop,linux]
redirect_from:
  - /2018/03/30/
---

大数据系统与大规模数据处理作业，要求环境:

- jdk-1.7
- ubuntu-14.04
- hadoop-2.6.0
- HBase-0.98

---

* Kramdown table of contents
{:toc .toc}

# Hadoop 环境配置

## JDK-1.7

我的 ubuntu 系统版本是 16.04 LTS，jdk 版本是 openjdk-1.8，要求版本是 1.7，需要切换 jdk 版本，但是 16.04 安装源已经没有 openjdk7 了，直接 sudo apt-get install openjdk-7-jdk 会提示 "没有可安装候选"，需要手动添加仓库:

- sudo add-apt-repository ppa:openjdk-r/ppa
- sudo apt-get update
- sudo apt-get install openjdk-7-jdk

然后可以随时切换 jdk 版本:

- sudo update-alternatives --config java
- sudo update-alternatives --config javac

## hadoop-2.6.5

在网上没找到 2.6.0 版本的 hadoop，所以将就着用 2.6.5 版本的，虽然全程按照网上的教程配置的，但也遇到了一些问题，以下是搭建伪分布式环境步骤:

### 查看 host 文件:

$$
\begin{array}{l}
\text{cat /etc/hosts}
\end{array}
$$

我的 hostname 是 localhost，这个名称待会用于配置文件，因为我搭建的是伪分布式环境，所以 master node 和 slave node 都是 localhost，如果要搭建完全分布式环境，要把每台机子的 host 名称以及 ip 都写入 hosts 文件里面。

### 免密码连入

免密码连入是为了让 node 之间的数据交流免除输入密码的限制，即使是伪分布式也要做到这一点。

$$
\begin{array}{l}
\text{ssh-keygen -t rsa} \\
\text{cd ~/.ssh} \\
\text{cp id_rsa.pub authorized_keys}
\end{array}
$$

按照网上的教程，到这里应该能够实现免密码 ssh localhost 才对，但是却报错误:

$$
\text{"sign_and_send_pubkey: signing failed: agent refused operation"}
$$

起初我怀疑是因为 authorized_keys 没有生效，所以取消了 /etc/ssh/sshd_config 里面的注释:

$$
\begin{array}{l}
\text{#AuthorizedKeysFile      %h/.ssh/authorized_keys}
\end{array}
$$

并更改权限:

$$
\begin{array}{l}
\text{chmod 700 ~/.ssh} \\
\text{chmod 600 ~/.ssh/authorized_keys}
\end{array}
$$

但仍没有解决上述问题，网上有一个解决方法:

$$
\begin{array}{l}
\text{eval “\$(ssh-agent)”} \\
\text{ssh-add}
\end{array}
$$

ssh-agent 用于管理密钥，ssh-add 将密钥加入到 ssh-agent 中，ssh 和 ssh-agent 通信获取密钥。

可以通过 $\text{ssh-add -l}$ 查看附加了哪些 key。

但这种方法只能在当前的 terminal 起作用，重新开一个 terminal 就得重新执行上述命令。

最终我重打开一个 terminal 直接执行:

$$
\begin{array}{l}
\text{ssh-add}
\end{array}
$$

竟然成功了，当然我也没弄懂其中缘由，可能这就是天意吧 :)

### 安装 hadoop-2.6.5

下载 hadoop-2.6.5.tar.gz 并解压:

$$
\begin{array}{l}
\text{tar xzvf hadoop-2.6.5.tar.gz ~/Hadoop/hadoop-2.6.5}
\end{array}
$$

然后在 hadoop-2.6.5 目录下修改以下文件:

$\text{./etc/hadoop/hadoop-env.sh}$

~~~xml
   export JAVA_HOME= /usr/lib/jvm/java-7-openjdk-amd64
~~~

$\text{./etc/hadoop/core-site.xml}$

$$
\begin{array}{l}
\text{1.设置 master 的 NameNode 的 IP 以及监听端口} \\
\text{2.设置存放每次运行的作业信息的临时目录。}
\end{array}
$$

~~~xml
<configuration>
	<property>
		<name>fs.default.name</name>
		<value>hdfs://localhost:9000</value>
		<final>true</final>
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/home/dervean/Hadoop/hadoop-2.6.5/tmp</value>
		<description>A base for other temporary directories</description>
	</property>
</configuration>
~~~

$\text{./etc/hadoop/hdfs-site.xml}$

$$
\begin{array}{l}
\text{1.设置 NameNode 存储元数据的目录} \\
\text{2.设置 DataNode 存放数据块的目录} \\
\text{3.设置副本数目} \\
\text{4.设置访问权限} \\
\text{注意必须使用规范的 URI 格式(即: file:/home/dervean/Hadoop/hadoop-2.6.5/data 不要缺失 "file:")}
\end{array}
$$

~~~xml
<configuration>
	<property>
		<name>dfs.name.dir</name>
		<value>file:/home/dervean/Hadoop/hadoop-2.6.5/name</value>
		<final>true</final>
	</property>
	<property>
		<name>dfs.data.dir</name>
		<value>file:/home/dervean/Hadoop/hadoop-2.6.5/data</value>
		<final>true</final>
	</property>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
		<final>true</final>
	</property>
	<property>
		<name>dfs.permissions</name>
		<value>false</value>
	</property>
</configuration>
~~~

$\text{./etc/hadoop/mapred-site.xml}$

$$
\begin{array}{l}
\text{设置 JobTracker 的 IP 以及监听端口} 
\end{array}
$$

~~~xml
<configuration>
	<property>
		<name>mapred.job.tracker</name>
		<value>localhost:9001</value>
	</property>
</configuration>
~~~

$\text{./etc/hadoop/slaves}$

$$
\begin{array}{l}
\text{因为是伪分布式，所以 slave 只有 localhost} 
\end{array}
$$

~~~xml
localhost
~~~
   
### 修改 /etc/profile

将 hadoop 相关命令加入系统变量:

$$
\begin{array}{l}
\text{export HADOOP_INSTALL=/home/dervean/Hadoop/hadoop-2.6.5} \\
\text{export PATH=\$PATH:\${HADOOP_INSTALL}/bin:\${HADOOP_INSTALL}/sbin}
\end{array}
$$

需要重启机器 或者 $\text{source profile}$，然后运行命令查看版本:

$$
\begin{array}{l}
\text{hadoop version} 
\end{array}
$$

### 尝试启动集群:

$$
\begin{array}{l}
\text{hadoop namenode -format}
\end{array}
$$

格式化操作**只需要一次**即可。

$$
\begin{array}{l}
\text{start-all.sh}
\end{array}
$$

查看启动情况:

$$
\begin{array}{l}
\text{jps}
\end{array}
$$

如果出现 NameNode、NodeManager、ResourceManager、SecondaryNameNode、DataNode 这五个进程则说明启动成功。

遇到一些问题的话可以从 hadoop-2.6.5 目录下的 logs 目录中查找相关内容。

### 运行示例代码

先在 hdfs 下准备数据文件:

$$
\begin{array}{l}
\text{hdfs dfs -mkdir in } \\
\text{hdfs dfs -mkdir out } \\
\text{hdfs dfs -mkdir in/wordCount } \\
\text{hdfs dfs -cp LICENCE.txt in/wordCount}
\end{array}
$$

这时候就可以尝试建立 JAVA 项目运行观看效果了。

首先导入 hadoop library，hadoop 的相关依赖包都在文件目录下的 share 子目录下。

以下是 JAVA 代码:
  
~~~java
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapred.*;
import org.apache.commons.logging.*;

import java.io.IOException;
import java.util.Iterator;
import java.util.StringTokenizer;

public class WordCount  {
    public static class Map extends MapReduceBase implements Mapper<LongWritable, Text, Text, IntWritable>{
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();
        @Override
        public void map(LongWritable longWritable, Text text, OutputCollector<Text, IntWritable> outputCollector, Reporter reporter) throws IOException {
            String line = text.toString();
            StringTokenizer tokenizer = new StringTokenizer(line);
            while(tokenizer.hasMoreTokens()){
                word.set(tokenizer.nextToken());
                outputCollector.collect(word,one);
            }
        }
    }

    public static class Reduce extends MapReduceBase implements Reducer<Text,IntWritable,Text, IntWritable>{
        @Override
        public void reduce(Text text, Iterator<IntWritable> iterator, OutputCollector<Text, IntWritable> outputCollector, Reporter reporter) throws IOException {
            int sum= 0;
            while(iterator.hasNext()){
                sum += iterator.next().get();
            }
            outputCollector.collect(text, new IntWritable(sum));
        }
    }

    public static void main(String[] args) throws Exception{
        JobConf conf = new JobConf(WordCount.class);
        conf.setJobName("wordCount");
        conf.setOutputKeyClass(Text.class);
        conf.setOutputValueClass(IntWritable.class);

        conf.setMapperClass(Map.class);
        conf.setReducerClass(Reduce.class);

        conf.setInputFormat(TextInputFormat.class);
        conf.setOutputFormat(TextOutputFormat.class);

        FileInputFormat.setInputPaths(conf,new Path(args[0]));
        FileOutputFormat.setOutputPath(conf, new Path(args[1]));

        JobClient.runJob(conf);
    }
}
~~~

最后运行时添加程序参数:

~~~java
hdfs://localhost:9000/user/dervean/in/wordCount/LICENCE.txt
hdfs://localhost:9000/user/dervean/out/wordCount
~~~

注意此时 $\text{out}$ 目录下没有 $\text{wordCount}$ 文件夹的，如果存在一定要删除(hadoop 为了防止已生成数据被不小心覆盖写入)。

顺利运行完毕之后可以查看结果:

$$
\begin{array}{l}
\text{hdfs dfs -cat out/wordCount/part-00000}
\end{array}
$$

## HBase-0.98

### 下载安装包

hbase-0.98.24-hadoop2-bin.tar.gz

### 环境变量

~~~xml
#hbase home
export HBASE_HOME=/home/dervean/Hadoop/hbase-0.98.24-hadoop2
export PATH=$PATH:${HBASE_HOME}/bin
~~~

### 配置文件

$\text{/conf/hbase-env.sh}$

~~~xml
# The java implementation to use.  Java 1.6 required.
export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
export HBASE_MANAGES_ZK=true
~~~

$\text{conf/hbase-site.xml}$

~~~xml
<configuration>
    <property>
        <name>hbase.rootdir</name>
        <!--配置在hdfs文件系统上hbase存储的路径-->
        <value>hdfs://localhost:9000/hbase</value>
        <!--配置hbase在HDFS文件系统中的工作目录，端口号一定与hadoop中core-site.xml文件一致 fs.default.name-->
    </property>
</configuration>

以上是伪分布模式的配置，不需要配置 zookeeper，如果是完全分布式模式的话还需要进一步配置：

<configuration>
    <property>
        <name>hbase.rootdir</name>
        <!--配置在hdfs文件系统上hbase存储的路径-->
        <value>hdfs://localhost:9000/hbase</value>
        <!--配置hbase在HDFS文件系统中的工作目录，端口号一定与hadoop中core-site.xml文件一致 fs.default.name-->
    </property>
    <property>
        <name>hbase.cluster.distributed</name>
        <value>true</value>
        <!--Hbase运行的方式是否为分布式模式-->
    </property>
    <property>
        <name>hbase.zookeeper.quorum</name>
        <!--配置zookeeper在哪个节点上-->
        <value>localhost</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
        <!--副本个数为1，因为伪分布式-->
    </property>
    <property>
        <name>hbase.zookeeper.property.dataDir</name>
        <value>/home/dervean/Hadoop/zookeeper_data</value>
        <!--指定一个运行hbase的用户有写入文件权限的目录作为zookeeper数据目录-->
    </property>
</configuration>
~~~

### 启动

- 启动hbase，在bin目录下执行命令

    - start-hbase.sh 

    - stop-hbase.sh 

- 执行jps，发现新增加了java进程 HMaster

- hbase version










